import os
import shutil
from object_detection import model_lib_v2, exporter_lib_v2
from object_detection.utils import config_util
from object_detection.protos import pipeline_pb2
from ..Data.TF_Record_Maker import convert_coco_to_tfrecord, PipelineConfigParams
from google.protobuf import text_format
from ..MISC.pipeline_Maker import generate_mobilenet_v2_pipeline
from ..Data.COCO import check_train_valid_json, LABELME_to_coco
from ..MISC.Tool import  *
import tempfile
import tensorflow as tf
import webbrowser
import psutil
import subprocess


def create_mbnetv2_pipeline_config(savepath,params: PipelineConfigParams, num_classes):
    """
    Táº¡o pipeline.config dá»±a trÃªn tham sá»‘ tá»« PipelineConfigParams.
    
    - Náº¿u `custom_config_file` Ä‘Æ°á»£c cung cáº¥p, sao chÃ©p nÃ³ thay vÃ¬ táº¡o má»›i.
    - Náº¿u khÃ´ng, tá»± Ä‘á»™ng sinh pipeline.config má»›i.

    Tráº£ vá»:
    - ÄÆ°á»ng dáº«n Ä‘áº¿n file pipeline.config Ä‘Ã£ táº¡o hoáº·c sao chÃ©p.
    """
    config_path = os.path.join(savepath, "pipeline.config")
    os.makedirs(savepath, exist_ok=True)

    if params.custom_config_file:
        if not os.path.isfile(params.custom_config_file):
            raise FileNotFoundError(f"Custom config file khÃ´ng tá»“n táº¡i: {params.custom_config_file}")
        shutil.copy(params.custom_config_file, config_path)
        print(f"ğŸ“„ ÄÃ£ sao chÃ©p file pipeline tá»«: {params.custom_config_file}")
        return config_path

    if params.model_resolution == 320:
        fineTunePath = os.path.join(get_pak_path(), "bin", "MobileNetV2_SSD",
                                    "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8",
                                    "checkpoint", "ckpt-0")
    elif params.model_resolution == 640:
        fineTunePath = os.path.join(get_pak_path(), "bin", "MobileNetV2_SSD",
                                    "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8",
                                    "checkpoint", "ckpt-0")
    else:
        raise ValueError("Unsupported model resolution. Choose either 320 or 640.")

    pipeline_config = generate_mobilenet_v2_pipeline(
        resolution=params.model_resolution,
        num_classes=num_classes,
        fine_tune_checkpoint=fineTunePath,
        batch_size=params.batch_size,
        learning_rate_base=params.learning_rate_base,
        total_steps=params.total_steps,
        label_map_path=params.label_map_path,
        train_input_path=params.train_input_path,
        vaild_input_path=params.vaild_input_path
    )

    with open(config_path, "w", encoding="utf-8") as f:
        f.write(pipeline_config)

    log_print(f"âœ… Pipeline config Ä‘Ã£ Ä‘Æ°á»£c táº¡o táº¡i: {config_path}")
    return config_path




class MobileNetV2_SSD:
    def __init__(self, datapath, savepath=None): 
        """
        Khá»Ÿi táº¡o MobileNetV2 SSD vá»›i Ä‘Æ°á»ng dáº«n dá»¯ liá»‡u vÃ  nÆ¡i lÆ°u mÃ´ hÃ¬nh.

        Args:
            datapath (str): ÄÆ°á»ng dáº«n tá»›i dataset (COCO hoáº·c LabelMe).
            savepath (str, optional): ÄÆ°á»ng dáº«n Ä‘á»ƒ lÆ°u model vÃ  checkpoint. Máº·c Ä‘á»‹nh: "MobileNetV2SSD_DATASET".
        """
        self.datapath = os.path.abspath(datapath)
        self.modelcp = None
        self.tensorboard_process = None  # Quáº£n lÃ½ TensorBoard

        if savepath is None:
            self.savepath = os.path.abspath("MobileNetV2SSD_DATASET")
        else:
            self.savepath = os.path.abspath(savepath)

        os.makedirs(self.savepath, exist_ok=True)

    def prepare_data(self, pipeline_params=None):
        """ Chuyá»ƒn Ä‘á»•i dataset sang Ä‘á»‹nh dáº¡ng TFRecord & táº¡o pipeline.config """
        if os.path.isdir(self.datapath):
            subdirs = os.listdir(self.datapath)
            if "train" in subdirs and "valid" in subdirs:
                log_print("ğŸ“‚ PhÃ¡t hiá»‡n Ä‘Ã¢y lÃ  1 COCO DATASET!")
                check_train_valid_json(self.datapath)
                save_path, pipeline, num_classes = convert_coco_to_tfrecord(
                    self.datapath, self.savepath, pipeline_params)
            else:
                TEMP_COCO = os.path.join(tempfile.gettempdir(), "CocoTEMP")
                log_print("ğŸ“‚ PhÃ¡t hiá»‡n Ä‘Ã¢y lÃ  LabelME Dataset, chuyá»ƒn Ä‘á»•i sang COCO...")
                LABELME_to_coco(self.datapath, TEMP_COCO)
                save_path, pipeline, num_classes = convert_coco_to_tfrecord(
                    TEMP_COCO, self.savepath, pipeline_params)
                shutil.rmtree(TEMP_COCO)

            create_mbnetv2_pipeline_config(save_path, pipeline, num_classes)

    def is_tensorboard_running(self, port=6006):
        """ Kiá»ƒm tra xem TensorBoard cÃ³ Ä‘ang cháº¡y trÃªn cá»•ng chá»‰ Ä‘á»‹nh khÃ´ng """
        for process in psutil.process_iter(attrs=['pid', 'name', 'cmdline']):
            if process.info['name'] and "tensorboard" in process.info['name'].lower():
                if any(f"--port={port}" in cmd for cmd in process.info['cmdline']):
                    return True
        return False

    def start_tensorboard(self, logdir, port=6006):
        """ Khá»Ÿi Ä‘á»™ng TensorBoard náº¿u chÆ°a cháº¡y """
        if self.is_tensorboard_running(port):
            log_print(f"âš ï¸ TensorBoard Ä‘Ã£ cháº¡y trÃªn cá»•ng {port}, bá» qua khá»Ÿi Ä‘á»™ng láº¡i.")
            return

        self.tensorboard_process = subprocess.Popen(
            ["tensorboard", f"--logdir={logdir}", f"--port={port}"],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )
        log_print(f"âœ… TensorBoard Ä‘ang cháº¡y táº¡i: http://localhost:{port}")

        try:
            webbrowser.open(f"http://localhost:{port}")
        except:
            log_print("âš ï¸ KhÃ´ng thá»ƒ má»Ÿ trÃ¬nh duyá»‡t tá»± Ä‘á»™ng, vui lÃ²ng truy cáº­p thá»§ cÃ´ng.")

    def stop_tensorboard(self):
        """ Dá»«ng TensorBoard khi chÆ°Æ¡ng trÃ¬nh káº¿t thÃºc """
        if self.tensorboard_process:
            log_print("ğŸ›‘ Äang táº¯t TensorBoard...")
            self.tensorboard_process.terminate()
            self.tensorboard_process.wait()
            log_print("âœ… TensorBoard Ä‘Ã£ dá»«ng.")

    def train(self, modelCheckPointDir=None, openTensorBroad=False, TensorBroadPort=6006,
              checkpoint_every_n=1000, checkpoint_max_to_keep=7, use_tpu=False, **kwargs):
        """ Huáº¥n luyá»‡n mÃ´ hÃ¬nh """
        if modelCheckPointDir is None:
            MODEL_DIR = os.path.join(self.savepath, "ModelCheckPoint")
        else:
            MODEL_DIR = os.path.abspath(modelCheckPointDir)

        self.modelcp = MODEL_DIR

        if openTensorBroad:
            logdir = os.path.join(MODEL_DIR, "train")
            self.start_tensorboard(logdir, TensorBroadPort)


        if tf.config.list_physical_devices('GPU'):
            device_name = tf.test.gpu_device_name()
            log_print(f"ğŸš€ Training on GPU: {device_name}")
        elif tf.config.list_physical_devices('TPU'):
            log_print("âš¡ Training on TPU")
        else:
            log_print("ğŸ’» Training on CPU")

        try:
            model_lib_v2.train_loop(
                pipeline_config_path=os.path.join(self.savepath, "pipeline.config"),
                model_dir=MODEL_DIR,
                use_tpu=use_tpu,
                checkpoint_every_n=checkpoint_every_n,
                checkpoint_max_to_keep=checkpoint_max_to_keep,
                **kwargs
            )
            log_print("âœ… ÄÃ£ HoÃ n ThÃ nh Train!")

        except KeyboardInterrupt:
            log_print("\nğŸ›‘ Dá»«ng training do ngÆ°á»i dÃ¹ng báº¥m Ctrl+C!")

        finally:
            self.stop_tensorboard()  

    def export_model(self, export_dir=None, checkpoint_path=None, get_latest_checkpoint=True):
        """ Xuáº¥t model Ä‘Ã£ train ra SavedModel format """

        if export_dir is None:
            export_dir = os.path.join(self.savepath, "exported_model")
        else:
            export_dir = os.path.abspath(export_dir)
        os.makedirs(export_dir, exist_ok=True)

        if checkpoint_path:
            checkpoint_path = os.path.abspath(checkpoint_path)
        elif get_latest_checkpoint:
            checkpoint_dirs = [self.modelcp, os.path.join(self.savepath, "ModelCheckPoint")]
            checkpoint_dirs = [os.path.abspath(d) for d in checkpoint_dirs if d]

            for path in checkpoint_dirs:
                if path and os.path.exists(path):
                    latest_ckpt = tf.train.latest_checkpoint(path)
                    if latest_ckpt:
                        checkpoint_path = latest_ckpt
                        break 


        if checkpoint_path is None:
            log_print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y checkpoint Ä‘á»ƒ xuáº¥t model!")
            return

        if not checkpoint_path.endswith(".index") and not checkpoint_path.endswith(".data-00000-of-00001"):
            checkpoint_base = checkpoint_path
            index_file = checkpoint_base + ".index"
            data_file = checkpoint_base + ".data-00000-of-00001"

            if os.path.exists(index_file) and os.path.exists(data_file):
                checkpoint_path = checkpoint_base
            else:
                log_print(f"âš ï¸ Checkpoint {checkpoint_base} khÃ´ng há»£p lá»‡! Thiáº¿u file .index hoáº·c .data")
                return

        log_print(f"ğŸ“Œ Äang sá»­ dá»¥ng checkpoint: {checkpoint_path}")

        pipeline_config_path = os.path.join(self.savepath, "pipeline.config")
        pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()

        with tf.io.gfile.GFile(pipeline_config_path, "r") as f:
            proto_str = f.read()
            text_format.Merge(proto_str, pipeline_config)

        exporter_lib_v2.export_inference_graph(
            input_type="image_tensor",
            pipeline_config=pipeline_config,  
            trained_checkpoint_dir=os.path.dirname(checkpoint_path),
            output_directory=export_dir
        )

        log_print(f"âœ… Model Ä‘Ã£ Ä‘Æ°á»£c xuáº¥t táº¡i: {export_dir}")

    def summary(self):
        """ Hiá»ƒn thá»‹ thÃ´ng tin tá»•ng quan vá» mÃ´ hÃ¬nh """
        print("\nğŸ“Œ **MobileNetV2 SSD Summary**")
        print(f"ğŸ“‚ Dataset Path: {self.datapath}")
        print(f"ğŸ’¾ Save Path: {self.savepath}")
        print(f"ğŸ“Œ Checkpoint Path: {self.modelcp if self.modelcp else 'ChÆ°a cÃ³ checkpoint nÃ o'}")
        print(f"ğŸ“Š TensorBoard: {'Äang cháº¡y' if self.is_tensorboard_running() else 'KhÃ´ng cháº¡y'}")
        
