import os
import shutil
from object_detection import model_lib_v2, exporter_lib_v2
from object_detection.utils import config_util
from object_detection.protos import pipeline_pb2
from ..Data.TF_Record_Maker import convert_coco_to_tfrecord, PipelineConfigParams
from google.protobuf import text_format
from ..MISC.pipeline_Maker import generate_mobilenet_v2_pipeline
from ..Data.COCO import check_train_valid_json, LABELME_to_coco
from ..MISC.Tool import  *
import tempfile
import tensorflow as tf
import webbrowser
import psutil
import subprocess


def create_mbnetv2_pipeline_config(savepath,params: PipelineConfigParams, num_classes):
    """
    T·∫°o pipeline.config d·ª±a tr√™n tham s·ªë t·ª´ PipelineConfigParams.
    
    - N·∫øu `custom_config_file` ƒë∆∞·ª£c cung c·∫•p, sao ch√©p n√≥ thay v√¨ t·∫°o m·ªõi.
    - N·∫øu kh√¥ng, t·ª± ƒë·ªông sinh pipeline.config m·ªõi.

    Tr·∫£ v·ªÅ:
    - ƒê∆∞·ªùng d·∫´n ƒë·∫øn file pipeline.config ƒë√£ t·∫°o ho·∫∑c sao ch√©p.
    """
    config_path = os.path.join(savepath, "pipeline.config")
    os.makedirs(savepath, exist_ok=True)

    if params.custom_config_file:
        if not os.path.isfile(params.custom_config_file):
            raise FileNotFoundError(f"Custom config file kh√¥ng t·ªìn t·∫°i: {params.custom_config_file}")
        shutil.copy(params.custom_config_file, config_path)
        print(f"üìÑ ƒê√£ sao ch√©p file pipeline t·ª´: {params.custom_config_file}")
        return config_path

    if params.model_resolution == 320:
        fineTunePath = os.path.join(get_pak_path(), "bin", "MobileNetV2_SSD",
                                    "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8",
                                    "checkpoint", "ckpt-0")
    elif params.model_resolution == 640:
        fineTunePath = os.path.join(get_pak_path(), "bin", "MobileNetV2_SSD",
                                    "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8",
                                    "checkpoint", "ckpt-0")
    else:
        raise ValueError("Unsupported model resolution. Choose either 320 or 640.")

    pipeline_config = generate_mobilenet_v2_pipeline(
        resolution=params.model_resolution,
        num_classes=num_classes,
        fine_tune_checkpoint=fineTunePath,
        batch_size=params.batch_size,
        learning_rate_base=params.learning_rate_base,
        total_steps=params.total_steps,
        label_map_path=params.label_map_path,
        train_input_path=params.train_input_path,
        vaild_input_path=params.vaild_input_path
    )

    with open(config_path, "w", encoding="utf-8") as f:
        f.write(pipeline_config)

    log_print(f"‚úÖ Pipeline config ƒë√£ ƒë∆∞·ª£c t·∫°o t·∫°i: {config_path}")
    return config_path




class MobileNetV2_SSD:
    def __init__(self, datapath, savepath=None): 
        """
        Kh·ªüi t·∫°o MobileNetV2 SSD v·ªõi ƒë∆∞·ªùng d·∫´n d·ªØ li·ªáu v√† n∆°i l∆∞u m√¥ h√¨nh.

        Args:
            datapath (str): ƒê∆∞·ªùng d·∫´n t·ªõi dataset (COCO ho·∫∑c LabelMe).
            savepath (str, optional): ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u model v√† checkpoint. M·∫∑c ƒë·ªãnh: "MobileNetV2SSD_DATASET".
        """
        self.datapath = os.path.abspath(datapath)
        self.modelcp = None
        self.tensorboard_process = None  # Qu·∫£n l√Ω TensorBoard

        if savepath is None:
            self.savepath = os.path.abspath("MobileNetV2SSD_DATASET")
        else:
            self.savepath = os.path.abspath(savepath)

        os.makedirs(self.savepath, exist_ok=True)

    def prepare_data(self, pipeline_params=None):
        """ Chuy·ªÉn ƒë·ªïi dataset sang ƒë·ªãnh d·∫°ng TFRecord & t·∫°o pipeline.config """
        if os.path.isdir(self.datapath):
            subdirs = os.listdir(self.datapath)
            if "train" in subdirs and "valid" in subdirs:
                log_print("üìÇ Ph√°t hi·ªán ƒë√¢y l√† 1 COCO DATASET!")
                check_train_valid_json(self.datapath)
                save_path, pipeline, num_classes = convert_coco_to_tfrecord(
                    self.datapath, self.savepath, pipeline_params)
            else:
                TEMP_COCO = os.path.join(tempfile.gettempdir(), "CocoTEMP")
                log_print("üìÇ Ph√°t hi·ªán ƒë√¢y l√† LabelME Dataset, chuy·ªÉn ƒë·ªïi sang COCO...")
                LABELME_to_coco(self.datapath, TEMP_COCO)
                save_path, pipeline, num_classes = convert_coco_to_tfrecord(
                    TEMP_COCO, self.savepath, pipeline_params)
                shutil.rmtree(TEMP_COCO)

            create_mbnetv2_pipeline_config(save_path, pipeline, num_classes)

    def is_tensorboard_running(self, port=6006):
        """ Ki·ªÉm tra xem TensorBoard c√≥ ƒëang ch·∫°y tr√™n c·ªïng ch·ªâ ƒë·ªãnh kh√¥ng """
        for process in psutil.process_iter(attrs=['pid', 'name', 'cmdline']):
            if process.info['name'] and "tensorboard" in process.info['name'].lower():
                if any(f"--port={port}" in cmd for cmd in process.info['cmdline']):
                    return True
        return False

    def start_tensorboard(self, logdir, port=6006):
        """ Kh·ªüi ƒë·ªông TensorBoard n·∫øu ch∆∞a ch·∫°y """
        if self.is_tensorboard_running(port):
            log_print(f"‚ö†Ô∏è TensorBoard ƒë√£ ch·∫°y tr√™n c·ªïng {port}, b·ªè qua kh·ªüi ƒë·ªông l·∫°i.")
            return

        self.tensorboard_process = subprocess.Popen(
            ["tensorboard", f"--logdir={logdir}", f"--port={port}"],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )
        log_print(f"‚úÖ TensorBoard ƒëang ch·∫°y t·∫°i: http://localhost:{port}")

        try:
            webbrowser.open(f"http://localhost:{port}")
        except:
            log_print("‚ö†Ô∏è Kh√¥ng th·ªÉ m·ªü tr√¨nh duy·ªát t·ª± ƒë·ªông, vui l√≤ng truy c·∫≠p th·ªß c√¥ng.")

    def stop_tensorboard(self):
        """ D·ª´ng TensorBoard khi ch∆∞∆°ng tr√¨nh k·∫øt th√∫c """
        if self.tensorboard_process:
            log_print("üõë ƒêang t·∫Øt TensorBoard...")
            self.tensorboard_process.terminate()
            self.tensorboard_process.wait()
            log_print("‚úÖ TensorBoard ƒë√£ d·ª´ng.")

    def train(self, modelCheckPointDir=None, openTensorBroad=False, TensorBroadPort=6006,
              checkpoint_every_n=1000, checkpoint_max_to_keep=7, use_tpu=False, **kwargs):
        """ Hu·∫•n luy·ªán m√¥ h√¨nh """
        if modelCheckPointDir is None:
            MODEL_DIR = os.path.join(self.savepath, "ModelCheckPoint")
        else:
            MODEL_DIR = os.path.abspath(modelCheckPointDir)

        self.modelcp = MODEL_DIR

        if openTensorBroad:
            logdir = os.path.join(MODEL_DIR, "train")
            self.start_tensorboard(logdir, TensorBroadPort)


        if tf.config.list_physical_devices('GPU'):
            device_name = tf.test.gpu_device_name()
            log_print(f"üöÄ Training on GPU: {device_name}")
        elif tf.config.list_physical_devices('TPU'):
            log_print("‚ö° Training on TPU")
        else:
            log_print("üíª Training on CPU")

        try:
            model_lib_v2.train_loop(
                pipeline_config_path=os.path.join(self.savepath, "pipeline.config"),
                model_dir=MODEL_DIR,
                use_tpu=use_tpu,
                checkpoint_every_n=checkpoint_every_n,
                checkpoint_max_to_keep=checkpoint_max_to_keep,
                **kwargs
            )
            log_print("‚úÖ ƒê√£ Ho√†n Th√†nh Train!")

        except KeyboardInterrupt:
            log_print("\nüõë D·ª´ng training do ng∆∞·ªùi d√πng b·∫•m Ctrl+C!")

        finally:
            self.stop_tensorboard()  

    def export_model(self, export_dir=None, checkpoint_path=None, get_latest_checkpoint=True):
        """ Xu·∫•t model ƒë√£ train ra SavedModel format """

        if export_dir is None:
            export_dir = os.path.join(self.savepath, "exported_model")
        else:
            export_dir = os.path.abspath(export_dir)
        os.makedirs(export_dir, exist_ok=True)

        if checkpoint_path:
            checkpoint_path = os.path.abspath(checkpoint_path)
        elif get_latest_checkpoint:
            checkpoint_dirs = [self.modelcp, os.path.join(self.savepath, "ModelCheckPoint")]
            checkpoint_dirs = [os.path.abspath(d) for d in checkpoint_dirs if d]

            for path in checkpoint_dirs:
                if path and os.path.exists(path):
                    latest_ckpt = tf.train.latest_checkpoint(path)
                    if latest_ckpt:
                        checkpoint_path = latest_ckpt
                        break 


        if checkpoint_path is None:
            log_print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y checkpoint ƒë·ªÉ xu·∫•t model!")
            return

        if not checkpoint_path.endswith(".index") and not checkpoint_path.endswith(".data-00000-of-00001"):
            checkpoint_base = checkpoint_path
            index_file = checkpoint_base + ".index"
            data_file = checkpoint_base + ".data-00000-of-00001"

            if os.path.exists(index_file) and os.path.exists(data_file):
                checkpoint_path = checkpoint_base
            else:
                log_print(f"‚ö†Ô∏è Checkpoint {checkpoint_base} kh√¥ng h·ª£p l·ªá! Thi·∫øu file .index ho·∫∑c .data")
                return

        log_print(f"üìå ƒêang s·ª≠ d·ª•ng checkpoint: {checkpoint_path}")

        pipeline_config_path = os.path.join(self.savepath, "pipeline.config")
        pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()

        with tf.io.gfile.GFile(pipeline_config_path, "r") as f:
            proto_str = f.read()
            text_format.Merge(proto_str, pipeline_config)

        exporter_lib_v2.export_inference_graph(
            input_type="image_tensor",
            pipeline_config=pipeline_config,  
            trained_checkpoint_dir=os.path.dirname(checkpoint_path),
            output_directory=export_dir
        )

        log_print(f"‚úÖ Model ƒë√£ ƒë∆∞·ª£c xu·∫•t t·∫°i: {export_dir}")

    def summary(self):
        """ Hi·ªÉn th·ªã th√¥ng tin t·ªïng quan v·ªÅ m√¥ h√¨nh """
        print("\nüìå **MobileNetV2 SSD Summary**")
        print(f"üìÇ Dataset Path: {self.datapath}")
        print(f"üíæ Save Path: {self.savepath}")
        print(f"üìå Checkpoint Path: {self.modelcp if self.modelcp else 'Ch∆∞a c√≥ checkpoint n√†o'}")
        print(f"üìä TensorBoard: {'ƒêang ch·∫°y' if self.is_tensorboard_running() else 'Kh√¥ng ch·∫°y'}")
        
