

import os
from object_detection import  exporter_lib_v2,model_lib_v2
from object_detection.protos import pipeline_pb2
from google.protobuf import text_format
from ..MISC.Tool import  *
import tensorflow as tf
import webbrowser
import psutil
import subprocess
from abc import ABC, abstractmethod

class BASE_MODEL:
    def __init__(self, datapath, savepath=None,modelName=None): 
        self.ModelName = "BaseModel" if not modelName else modelName.replace(" ", "_")
        """
        Kh·ªüi t·∫°o MobileNetV2 SSD v·ªõi ƒë∆∞·ªùng d·∫´n d·ªØ li·ªáu v√† n∆°i l∆∞u m√¥ h√¨nh.

        Args:
            datapath (str): ƒê∆∞·ªùng d·∫´n t·ªõi dataset (COCO ho·∫∑c LabelMe).
            savepath (str, optional): ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u model v√† checkpoint. M·∫∑c ƒë·ªãnh: "MobileNetV2SSD_DATASET".
        """
        self.datapath = os.path.abspath(datapath)
        self.modelcp = None
        self.tensorboard_process = None  # Qu·∫£n l√Ω TensorBoard

        if savepath is None:
            self.savepath = os.path.abspath(self.ModelName+"_SAVE")
        else:
            self.savepath = os.path.abspath(savepath)

        os.makedirs(self.savepath, exist_ok=True)

    @abstractmethod
    def prepare_data(self, pipeline_params):
        pass
    
    def is_tensorboard_running(self, port=6006):
        """ Ki·ªÉm tra xem TensorBoard c√≥ ƒëang ch·∫°y tr√™n c·ªïng ch·ªâ ƒë·ªãnh kh√¥ng """
        for process in psutil.process_iter(attrs=['pid', 'name', 'cmdline']):
            if process.info['name'] and "tensorboard" in process.info['name'].lower():
                if any(f"--port={port}" in cmd for cmd in process.info['cmdline']):
                    return True
        return False

    def start_tensorboard(self, logdir, port=6006):
        """ Kh·ªüi ƒë·ªông TensorBoard n·∫øu ch∆∞a ch·∫°y """
        if self.is_tensorboard_running(port):
            log_print(f"‚ö†Ô∏è TensorBoard ƒë√£ ch·∫°y tr√™n c·ªïng {port}, b·ªè qua kh·ªüi ƒë·ªông l·∫°i.")
            return

        self.tensorboard_process = subprocess.Popen(
            ["tensorboard", f"--logdir={logdir}", f"--port={port}"],
            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
        )
        log_print(f"‚úÖ TensorBoard ƒëang ch·∫°y t·∫°i: http://localhost:{port}")

        try:
            webbrowser.open(f"http://localhost:{port}")
        except:
            log_print("‚ö†Ô∏è Kh√¥ng th·ªÉ m·ªü tr√¨nh duy·ªát t·ª± ƒë·ªông, vui l√≤ng truy c·∫≠p th·ªß c√¥ng.")

    def stop_tensorboard(self):
        """ D·ª´ng TensorBoard khi ch∆∞∆°ng tr√¨nh k·∫øt th√∫c """
        if self.tensorboard_process:
            log_print("üõë ƒêang t·∫Øt TensorBoard...")
            self.tensorboard_process.terminate()
            self.tensorboard_process.wait()
            log_print("‚úÖ TensorBoard ƒë√£ d·ª´ng.")

    def train(self, modelCheckPointDir=None, openTensorBroad=False, TensorBroadPort=6006,
             checkpoint_every_n=1000, checkpoint_max_to_keep=7, use_tpu=False, **kwargs):
       """ Hu·∫•n luy·ªán m√¥ h√¨nh """
       if modelCheckPointDir is None:
           MODEL_DIR = os.path.join(self.savepath, "ModelCheckPoint")
       else:
           MODEL_DIR = os.path.abspath(modelCheckPointDir)
       self.modelcp = MODEL_DIR
       if openTensorBroad:
           logdir = os.path.join(MODEL_DIR, "train")
           self.start_tensorboard(logdir, TensorBroadPort)
       if tf.config.list_physical_devices('GPU'):
           device_name = tf.test.gpu_device_name()
           log_print(f"üöÄ Training on GPU: {device_name}")
       elif tf.config.list_physical_devices('TPU'):
           log_print("‚ö° Training on TPU")
       else:
           log_print("üíª Training on CPU")
       try:
           model_lib_v2.train_loop(
               pipeline_config_path=os.path.join(self.savepath, "pipeline.config"),
               model_dir=MODEL_DIR,
               use_tpu=use_tpu,
               checkpoint_every_n=checkpoint_every_n,
               checkpoint_max_to_keep=checkpoint_max_to_keep,
               **kwargs
           )
           log_print("‚úÖ ƒê√£ Ho√†n Th√†nh Train!")
       except KeyboardInterrupt:
           log_print("\nüõë D·ª´ng training do ng∆∞·ªùi d√πng b·∫•m Ctrl+C!")
       finally:
           self.stop_tensorboard()  
    

    def export_model(self, export_dir=None, checkpoint_path=None, get_latest_checkpoint=True,input_type="image_tensor",**kwargs):
        """ Xu·∫•t model ƒë√£ train ra SavedModel format """

        if export_dir is None:
            export_dir = os.path.join(self.savepath, "exported_model")
        else:
            export_dir = os.path.abspath(export_dir)
        os.makedirs(export_dir, exist_ok=True)

        if checkpoint_path:
            checkpoint_path = os.path.abspath(checkpoint_path)
        elif get_latest_checkpoint:
            checkpoint_dirs = [self.modelcp, os.path.join(self.savepath, "ModelCheckPoint")]
            checkpoint_dirs = [os.path.abspath(d) for d in checkpoint_dirs if d]

            for path in checkpoint_dirs:
                if path and os.path.exists(path):
                    latest_ckpt = tf.train.latest_checkpoint(path)
                    if latest_ckpt:
                        checkpoint_path = latest_ckpt
                        break 


        if checkpoint_path is None:
            log_print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y checkpoint ƒë·ªÉ xu·∫•t model!")
            return

        if not checkpoint_path.endswith(".index") and not checkpoint_path.endswith(".data-00000-of-00001"):
            checkpoint_base = checkpoint_path
            index_file = checkpoint_base + ".index"
            data_file = checkpoint_base + ".data-00000-of-00001"

            if os.path.exists(index_file) and os.path.exists(data_file):
                checkpoint_path = checkpoint_base
            else:
                log_print(f"‚ö†Ô∏è Checkpoint {checkpoint_base} kh√¥ng h·ª£p l·ªá! Thi·∫øu file .index ho·∫∑c .data")
                return

        log_print(f"üìå ƒêang s·ª≠ d·ª•ng checkpoint: {checkpoint_path}")

        pipeline_config_path = os.path.join(self.savepath, "pipeline.config")
        pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()

        with tf.io.gfile.GFile(pipeline_config_path, "r") as f:
            proto_str = f.read()
            text_format.Merge(proto_str, pipeline_config)

        exporter_lib_v2.export_inference_graph(
            input_type=input_type,
            pipeline_config=pipeline_config,  
            trained_checkpoint_dir=os.path.dirname(checkpoint_path),
            output_directory=export_dir,
            **kwargs
        )

        log_print(f"‚úÖ Model ƒë√£ ƒë∆∞·ª£c xu·∫•t t·∫°i: {export_dir}")

    def evaluate(self, checkpoint_path=None,get_latest_checkpoint=True, eval_timeout=None, eval_interval=300,**kwargs):
        """
        ƒê√°nh gi√° m√¥ h√¨nh v·ªõi b·ªô d·ªØ li·ªáu validation.
    
        Args:
            checkpoint_dir (str, optional): ƒê∆∞·ªùng d·∫´n t·ªõi checkpoint c·∫ßn ƒë√°nh gi√°. M·∫∑c ƒë·ªãnh: checkpoint m·ªõi nh·∫•t trong th∆∞ m·ª•c model.
            eval_timeout (int, optional): Th·ªùi gian t·ªëi ƒëa ch·∫°y evaluation (gi√¢y). N·∫øu None, s·∫Ω ch·∫°y m√£i.
            eval_interval (int, optional): Kho·∫£ng th·ªùi gian gi·ªØa c√°c l·∫ßn ƒë√°nh gi√° (gi√¢y). M·∫∑c ƒë·ªãnh: 300 gi√¢y (5 ph√∫t).
        """
        if checkpoint_path:
            checkpoint_path = os.path.abspath(checkpoint_path)
        elif get_latest_checkpoint:
            checkpoint_dirs = [self.modelcp, os.path.join(self.savepath, "ModelCheckPoint")]
            checkpoint_dirs = [os.path.abspath(d) for d in checkpoint_dirs if d]

            for path in checkpoint_dirs:
                if path and os.path.exists(path):
                    latest_ckpt = tf.train.latest_checkpoint(path)
                    if latest_ckpt:
                        checkpoint_path = latest_ckpt
                        break 


        if checkpoint_path is None:
            log_print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y checkpoint ƒë·ªÉ xu·∫•t model!")
            return

        if not checkpoint_path.endswith(".index") and not checkpoint_path.endswith(".data-00000-of-00001"):
            checkpoint_base = checkpoint_path
            index_file = checkpoint_base + ".index"
            data_file = checkpoint_base + ".data-00000-of-00001"

            if os.path.exists(index_file) and os.path.exists(data_file):
                checkpoint_path = checkpoint_base
            else:
                log_print(f"‚ö†Ô∏è Checkpoint {checkpoint_base} kh√¥ng h·ª£p l·ªá! Thi·∫øu file .index ho·∫∑c .data")
                return

        log_print(f"üìå ƒêang s·ª≠ d·ª•ng checkpoint: {checkpoint_path}")
        
        try:
            model_lib_v2.eval_continuously(
                pipeline_config_path=os.path.join(self.savepath, "pipeline.config"),
                model_dir=self.savepath,
                checkpoint_dir=os.path.dirname(checkpoint_path),
                wait_interval=eval_interval,
                timeout=eval_timeout,
                **kwargs
            )
            log_print("‚úÖ ƒê√°nh gi√° m√¥ h√¨nh ho√†n t·∫•t!")
        except KeyboardInterrupt:
            log_print("\nüõë ƒê√°nh gi√° b·ªã h·ªßy b·ªüi ng∆∞·ªùi d√πng!")
    
    def summary(self):
        """ Hi·ªÉn th·ªã th√¥ng tin t·ªïng quan v·ªÅ m√¥ h√¨nh """
        log_print(f"\nüìå **{self.ModelName} Summary**")
        log_print(f"üìÇ Dataset Path: {self.datapath}")
        log_print(f"üíæ Save Path: {self.savepath}")
        log_print(f"üìå Checkpoint Path: {self.modelcp if self.modelcp else 'Ch∆∞a c√≥ checkpoint n√†o'}")
        log_print(f"üìä TensorBoard: {'ƒêang ch·∫°y' if self.is_tensorboard_running() else 'Kh√¥ng ch·∫°y'}")